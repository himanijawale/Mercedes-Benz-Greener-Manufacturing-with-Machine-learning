{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIPTION\n",
    "\n",
    "#Reduce the time a Mercedes-Benz spends on the test bench.\n",
    "\n",
    "#Problem Statement Scenario:\n",
    "#Since the first automobile, the Benz Patent Motor Car in 1886, Mercedes-Benz has stood for important automotive innovations. These include the passenger safety cell with a crumple zone, the airbag, and intelligent assistance systems. Mercedes-Benz applies for nearly 2000 patents per year, making the brand the European leader among premium carmakers. Mercedes-Benz is the leader in the premium car industry. With a huge selection of features and options, customers can choose the customized Mercedes-Benz of their dreams.\n",
    "\n",
    "#To ensure the safety and reliability of every unique car configuration before they hit the road, the company’s engineers have developed a robust testing system. As one of the world’s biggest manufacturers of premium cars, safety and efficiency are paramount on Mercedes-Benz’s production lines. However, optimizing the speed of their testing system for many possible feature combinations is complex and time-consuming without a powerful algorithmic approach.\n",
    "\n",
    "#You are required to reduce the time that cars spend on the test bench. Others will work with a dataset representing different permutations of features in a Mercedes-Benz car to predict the time it takes to pass testing. Optimal algorithms will contribute to faster testing, resulting in lower carbon dioxide emissions without reducing Mercedes-Benz’s standards.\n",
    "\n",
    "#Following actions should be performed:\n",
    "\n",
    "#If for any column(s), the variance is equal to zero, then you need to remove those variable(s).\n",
    "#Check for null and unique values for test and train sets.\n",
    "#Apply label encoder.\n",
    "#Perform dimensionality reduction.\n",
    "#Predict your test_df values using XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
      "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
      "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
      "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
      "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
      "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
      "\n",
      "   X380  X382  X383  X384  X385  \n",
      "0     0     0     0     0     0  \n",
      "1     0     0     0     0     0  \n",
      "2     0     1     0     0     0  \n",
      "3     0     0     0     0     0  \n",
      "4     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 378 columns] (4209, 378)\n"
     ]
    }
   ],
   "source": [
    "# Read the training dataset\n",
    "df_train = pd.read_csv(\"train/train.csv\")\n",
    "\n",
    "# Display some observations from training dataset\n",
    "print(df_train.head(), df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   ID  X0 X1  X2 X3 X4 X5 X6 X8  X10  ...  X375  X376  X377  X378  X379  X380  \\\n",
       " 0   1  az  v   n  f  d  t  a  w    0  ...     0     0     0     1     0     0   \n",
       " 1   2   t  b  ai  a  d  b  g  y    0  ...     0     0     1     0     0     0   \n",
       " 2   3  az  v  as  f  d  a  j  j    0  ...     0     0     0     1     0     0   \n",
       " 3   4  az  l   n  f  d  z  l  n    0  ...     0     0     0     1     0     0   \n",
       " 4   5   w  s  as  c  d  y  i  m    0  ...     1     0     0     0     0     0   \n",
       " \n",
       "    X382  X383  X384  X385  \n",
       " 0     0     0     0     0  \n",
       " 1     0     0     0     0  \n",
       " 2     0     0     0     0  \n",
       " 3     0     0     0     0  \n",
       " 4     0     0     0     0  \n",
       " \n",
       " [5 rows x 377 columns],\n",
       " (4209, 377))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test dataset\n",
    "df_test = pd.read_csv(\"test/test.csv\")\n",
    "\n",
    "# Display some observations from test dataset\n",
    "df_test.head(),df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64      369\n",
      "object       8\n",
      "float64      1\n",
      "dtype: int64\n",
      "int64     369\n",
      "object      8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for datatypes of columns from train and test datasets\n",
    "print(df_train.dtypes.value_counts())\n",
    "print(df_test.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for null and unique values for test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      0.0\n",
       "X262    0.0\n",
       "X261    0.0\n",
       "X260    0.0\n",
       "X259    0.0\n",
       "       ... \n",
       "X125    0.0\n",
       "X124    0.0\n",
       "X123    0.0\n",
       "X132    0.0\n",
       "X385    0.0\n",
       "Length: 378, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in training dataset\n",
    "df_train.isnull().mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No null values are present in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      0.0\n",
       "X262    0.0\n",
       "X261    0.0\n",
       "X260    0.0\n",
       "X259    0.0\n",
       "       ... \n",
       "X125    0.0\n",
       "X124    0.0\n",
       "X123    0.0\n",
       "X132    0.0\n",
       "X385    0.0\n",
       "Length: 377, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in training dataset\n",
    "df_test.isnull().mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No null values are present in the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X0    X1    X2    X3    X4    X5    X6    X8\n",
      "count   4209  4209  4209  4209  4209  4209  4209  4209\n",
      "unique    47    27    44     7     4    29    12    25\n",
      "top        z    aa    as     c     d     w     g     j\n",
      "freq     360   833  1659  1942  4205   231  1042   277\n",
      "Unique values from train datasets in X0:\n",
      "['k' 'az' 't' 'al' 'o' 'w' 'j' 'h' 's' 'n' 'ay' 'f' 'x' 'y' 'aj' 'ak' 'am'\n",
      " 'z' 'q' 'at' 'ap' 'v' 'af' 'a' 'e' 'ai' 'd' 'aq' 'c' 'aa' 'ba' 'as' 'i'\n",
      " 'r' 'b' 'ax' 'bc' 'u' 'ad' 'au' 'm' 'l' 'aw' 'ao' 'ac' 'g' 'ab']\n",
      "\n",
      "\n",
      "Unique values from train datasets in X1:\n",
      "['v' 't' 'w' 'b' 'r' 'l' 's' 'aa' 'c' 'a' 'e' 'h' 'z' 'j' 'o' 'u' 'p' 'n'\n",
      " 'i' 'y' 'd' 'f' 'm' 'k' 'g' 'q' 'ab']\n",
      "\n",
      "\n",
      "Unique values from train datasets in X2:\n",
      "['at' 'av' 'n' 'e' 'as' 'aq' 'r' 'ai' 'ak' 'm' 'a' 'k' 'ae' 's' 'f' 'd'\n",
      " 'ag' 'ay' 'ac' 'ap' 'g' 'i' 'aw' 'y' 'b' 'ao' 'al' 'h' 'x' 'au' 't' 'an'\n",
      " 'z' 'ah' 'p' 'am' 'j' 'q' 'af' 'l' 'aa' 'c' 'o' 'ar']\n",
      "\n",
      "\n",
      "Unique values from train datasets in X3:\n",
      "['a' 'e' 'c' 'f' 'd' 'b' 'g']\n",
      "\n",
      "\n",
      "Unique values from train datasets in X4:\n",
      "['d' 'b' 'c' 'a']\n",
      "\n",
      "\n",
      "Unique values from train datasets in X5:\n",
      "['u' 'y' 'x' 'h' 'g' 'f' 'j' 'i' 'd' 'c' 'af' 'ag' 'ab' 'ac' 'ad' 'ae'\n",
      " 'ah' 'l' 'k' 'n' 'm' 'p' 'q' 's' 'r' 'v' 'w' 'o' 'aa']\n",
      "\n",
      "\n",
      "Unique values from train datasets in X6:\n",
      "['j' 'l' 'd' 'h' 'i' 'a' 'g' 'c' 'k' 'e' 'f' 'b']\n",
      "\n",
      "\n",
      "Unique values from train datasets in X8:\n",
      "['o' 'x' 'e' 'n' 's' 'a' 'h' 'p' 'm' 'k' 'd' 'i' 'v' 'j' 'b' 'q' 'w' 'g'\n",
      " 'y' 'l' 'f' 'u' 'r' 't' 'c']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for unique values for train and test sets\n",
    "d = df_train.describe(include = 'O')\n",
    "print(d)\n",
    "\n",
    "for c in d.columns:\n",
    "    print(\"Unique values from train datasets in \" + c +\":\")\n",
    "    print(df_train[c].unique())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X0    X1    X2    X3    X4    X5    X6    X8\n",
      "count   4209  4209  4209  4209  4209  4209  4209  4209\n",
      "unique    49    27    45     7     4    32    12    25\n",
      "top       ak    aa    as     c     d     v     g     e\n",
      "freq     432   826  1658  1900  4203   246  1073   274\n",
      "Unique values from test datasets in X0:\n",
      "['az' 't' 'w' 'y' 'x' 'f' 'ap' 'o' 'ay' 'al' 'h' 'z' 'aj' 'd' 'v' 'ak'\n",
      " 'ba' 'n' 'j' 's' 'af' 'ax' 'at' 'aq' 'av' 'm' 'k' 'a' 'e' 'ai' 'i' 'ag'\n",
      " 'b' 'am' 'aw' 'as' 'r' 'ao' 'u' 'l' 'c' 'ad' 'au' 'bc' 'g' 'an' 'ae' 'p'\n",
      " 'bb']\n",
      "\n",
      "\n",
      "Unique values from test datasets in X1:\n",
      "['v' 'b' 'l' 's' 'aa' 'r' 'a' 'i' 'p' 'c' 'o' 'm' 'z' 'e' 'h' 'w' 'g' 'k'\n",
      " 'y' 't' 'u' 'd' 'j' 'q' 'n' 'f' 'ab']\n",
      "\n",
      "\n",
      "Unique values from test datasets in X2:\n",
      "['n' 'ai' 'as' 'ae' 's' 'b' 'e' 'ak' 'm' 'a' 'aq' 'ag' 'r' 'k' 'aj' 'ay'\n",
      " 'ao' 'an' 'ac' 'af' 'ax' 'h' 'i' 'f' 'ap' 'p' 'au' 't' 'z' 'y' 'aw' 'd'\n",
      " 'at' 'g' 'am' 'j' 'x' 'ab' 'w' 'q' 'ah' 'ad' 'al' 'av' 'u']\n",
      "\n",
      "\n",
      "Unique values from test datasets in X3:\n",
      "['f' 'a' 'c' 'e' 'd' 'g' 'b']\n",
      "\n",
      "\n",
      "Unique values from test datasets in X4:\n",
      "['d' 'b' 'a' 'c']\n",
      "\n",
      "\n",
      "Unique values from test datasets in X5:\n",
      "['t' 'b' 'a' 'z' 'y' 'x' 'h' 'g' 'f' 'j' 'i' 'd' 'c' 'af' 'ag' 'ab' 'ac'\n",
      " 'ad' 'ae' 'ah' 'l' 'k' 'n' 'm' 'p' 'q' 's' 'r' 'v' 'w' 'o' 'aa']\n",
      "\n",
      "\n",
      "Unique values from test datasets in X6:\n",
      "['a' 'g' 'j' 'l' 'i' 'd' 'f' 'h' 'c' 'k' 'e' 'b']\n",
      "\n",
      "\n",
      "Unique values from test datasets in X8:\n",
      "['w' 'y' 'j' 'n' 'm' 's' 'a' 'v' 'r' 'o' 't' 'h' 'c' 'k' 'p' 'u' 'd' 'g'\n",
      " 'b' 'q' 'e' 'l' 'f' 'i' 'x']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = df_test.describe(include = 'O')\n",
    "print(d)\n",
    "          \n",
    "for c in d.columns:\n",
    "    print(\"Unique values from test datasets in \" + c +\":\")\n",
    "    print(df_test[c].unique())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For numerical variables in train and test datasets, [0,1] only two unique values are there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If for any column(s), the variance is equal to zero, then you need to remove those variable(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8418, 377), (4209, 377), (4209, 377))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine train annd test datasets\n",
    "X_train = pd.DataFrame(df_train[df_train.columns.difference(['y'])])\n",
    "cat_df = X_train.append(df_test, ignore_index=True)\n",
    "cat_df.shape,X_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.std()[X_train.std() <= 0.0].index.values))\n",
    "print(len(df_test.std()[df_test.std() <= 0.0].index.values))\n",
    "print(len(cat_df.std()[cat_df.std() <= 0.0].index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X107' 'X11' 'X233' 'X235' 'X268' 'X289' 'X290' 'X293' 'X297' 'X330'\n",
      " 'X347' 'X93']\n",
      "['X257' 'X258' 'X295' 'X296' 'X369']\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(X_train.std()[X_train.std() <= 0.0].index.values))\n",
    "print(np.sort(df_test.std()[df_test.std() <= 0.0].index.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To apply VarianceThreshold all columns should be numerical. So Lets apply label encoder to categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the ordinal encoder from sklearn.preprocessing library to encode the categorical variable\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "en = OrdinalEncoder(encoding_method='arbitrary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder(encoding_method='arbitrary',\n",
       "               variables=['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with combined dataframe\n",
    "en.fit(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply trained encoder on dataset\n",
    "cat_df=en.transform(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64    377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out columns with zero variances and delete such a columns from combined datasets.\n",
    "### Use VarianceThreshold function from sklearn.feature_selection library to check for columns with 0 variance and remove them by applying it on dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import variancethreshold function and initialize the variable\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var = VarianceThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on combined datasets\n",
    "var.fit(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following will print the number of columns which does not have 0 variance.\n",
    "len(cat_df.columns[var.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 377 columns in combined dataset. The output for above command gives us number of columns which satisfy threshold level. From the above output we can conclude that no column from combined datasets (train and test datasets) have 0 variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split combined dataset into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cat_df.iloc[:len(X_train),:]\n",
    "X_test = cat_df.iloc[len(X_train):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4209, 377), (4209, 377))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_train['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sc.transform(X)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to get dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([324.24603556, 294.1457667 , 261.89624398, 230.05052225,\n",
       "       223.79339169, 220.57055802, 209.85744827, 180.66321674,\n",
       "       173.84795852, 165.52920968, 158.48076052, 154.29711786,\n",
       "       150.28412646, 148.63433365, 143.47980558])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22782181e+01, -2.11063524e+00, -1.03292151e+00, ...,\n",
       "         2.30021140e+01,  5.31864719e+01,  2.53742412e+01],\n",
       "       [-1.86763357e-01,  2.57030612e-01,  7.93991320e-01, ...,\n",
       "         4.08022070e+00,  1.78854639e+00,  1.20066843e+00],\n",
       "       [ 9.14372824e+00,  2.19004478e+01, -3.55806391e+00, ...,\n",
       "         4.00934696e+00, -8.20861084e-01,  6.85479372e-01],\n",
       "       ...,\n",
       "       [ 7.66916566e-03,  5.63696820e-01,  3.32790790e+00, ...,\n",
       "        -3.16123813e-01, -5.32296221e+00,  2.04744517e+00],\n",
       "       [-1.52479515e+00,  3.62995808e-01, -4.17237418e-01, ...,\n",
       "        -1.20856058e+00,  1.07469819e-01, -4.71692927e-01],\n",
       "       [-1.86978192e+00, -1.15907159e+00, -4.21989305e-01, ...,\n",
       "         1.48897470e+00, -5.94482497e-01, -9.93191496e-01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.440066  , 20.34425894, -4.97333348, ...,  5.70978141,\n",
       "        20.51588061, 10.5543026 ],\n",
       "       [ 2.24615275, -4.77063423, -9.5705276 , ...,  4.07940043,\n",
       "        23.41695428,  8.38713087],\n",
       "       [ 5.27955459, 17.07578525, -2.81449315, ..., 11.56832401,\n",
       "        21.36984777,  9.34891225],\n",
       "       ...,\n",
       "       [-2.72428665,  0.25981236,  3.0478758 , ..., -0.98463886,\n",
       "         0.16750156,  0.85490311],\n",
       "       [-1.62252457, -0.06800897,  3.91015124, ...,  0.07299109,\n",
       "         0.37797241, -0.4970986 ],\n",
       "       [-1.16457512, -1.63733295, -3.23993193, ...,  1.54621706,\n",
       "        -1.00656069,  0.96025204]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict your test_df values using XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import XGboost regressor from xgboost library\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict values of target variable for train dataset\n",
    "y_pred = xgb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919624286886962\n"
     ]
    }
   ],
   "source": [
    "#Check for performance metrics\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### r2_score gives us performance over 90% for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values of target variables for test dataset\n",
    "y_pred1 = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values are: \n",
      "[ 67.82372  110.092094  73.08562  ...  96.45536  108.67444  108.55392 ]\n"
     ]
    }
   ],
   "source": [
    "#Display values of predicted target values\n",
    "print(\"The predicted values are: \")\n",
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above are the predicted values for test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
